"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
exports.extractFrom = void 0;
const minipass_1 = require("minipass");
const strict_1 = require("node:assert/strict");
const node_crypto_1 = require("node:crypto");
const node_fs_1 = require("node:fs");
const promises_1 = require("node:fs/promises");
const node_http_1 = require("node:http");
const node_https_1 = require("node:https");
const node_path_1 = require("node:path");
const promises_2 = require("node:stream/promises");
const tar_1 = require("tar");
const unzipper_1 = require("unzipper");
const download_1 = require("./download.cjs");
const types_1 = require("./types.cjs");
const utils_1 = require("./utils.cjs");
/**
 * Extracts the binaries from the given URL and writes them to the destination.
 *
 * @param url - The URL of the archive to extract the binaries from
 * @param binaries - The list of binaries to extract
 * @param dir - The destination directory
 * @param checksums - The checksums to verify the binaries against
 * @returns The list of binaries extracted
 */
/**
 * Extracts the binaries from the given URL and writes them to the destination.
 *
 * @param url - The URL of the archive to extract the binaries from
 * @param binaries - The list of binaries to extract
 * @param dir - The destination directory
 * @param checksums - The checksums to verify the binaries against
 * @returns The list of binaries extracted
 */
async function extractFrom(url, binaries, dir, checksums) {
    const extract = url.pathname.toLowerCase().endsWith(types_1.Extension.Tar)
        ? extractFromTar
        : extractFromZip;
    // write all files to a temporary directory first, then rename to the final
    // destination to avoid accidental partial extraction. We don't use
    // `os.tmpdir` for this because `rename` will fail if the directories are on
    // different file systems.
    const tempDir = `${dir}.downloading`;
    const rmOpts = { recursive: true, maxRetries: 3, force: true };
    try {
        // clean up any previous in-progress downloads
        await (0, promises_1.rm)(tempDir, rmOpts);
        // make the temporary directory to extract the binaries to
        await (0, promises_1.mkdir)(tempDir, { recursive: true });
        const downloads = await extract(url, binaries, tempDir, checksums?.algorithm);
        (0, strict_1.ok)(downloads.length === binaries.length, 'Failed to extract all binaries');
        const paths = [];
        for (const { path, binary, checksum } of downloads) {
            if (checksums) {
                (0, utils_1.say)(`verifying checksum for ${binary}`);
                const expected = checksums.binaries[binary];
                if (checksum === expected) {
                    (0, utils_1.say)(`checksum verified for ${binary}`);
                }
                else {
                    throw new Error(`checksum mismatch for ${binary}, expected ${expected}, got ${checksum}`);
                }
            }
            // add the *final* path to the list of binaries
            paths.push((0, node_path_1.join)(dir, (0, node_path_1.relative)(tempDir, path)));
        }
        // this directory shouldn't exist, but if two simultaneous `yarn foundryup`
        // processes are running, it might. Last process wins, so we remove other
        // `dir`s just in case.
        await (0, promises_1.rm)(dir, rmOpts);
        // everything has been extracted; move the files to their final destination
        await (0, promises_1.rename)(tempDir, dir);
        // return the list of extracted binaries
        return paths;
    }
    catch (error) {
        // if things fail for any reason try to clean up a bit. it is very important
        // to not leave `dir` behind, as its existence is a signal that the binaries
        // are installed.
        const rmErrors = (await Promise.allSettled([(0, promises_1.rm)(tempDir, rmOpts), (0, promises_1.rm)(dir, rmOpts)]))
            .filter((r) => r.status === 'rejected')
            .map((r) => r.reason);
        // if we failed to clean up, create an aggregate error message
        if (rmErrors.length) {
            throw new AggregateError([error, ...rmErrors], 'This is a bug; you should report it.');
        }
        throw error;
    }
}
exports.extractFrom = extractFrom;
/**
 * Extracts the binaries from a tar archive.
 *
 * @param url - The URL of the archive to extract the binaries from
 * @param binaries - The list of binaries to extract
 * @param dir - The destination directory
 * @param checksumAlgorithm - The checksum algorithm to use
 * @returns The list of binaries extracted
 */
/**
 * Extracts the binaries from a tar archive.
 *
 * @param url - The URL of the archive to extract the binaries from
 * @param binaries - The list of binaries to extract
 * @param dir - The destination directory
 * @param checksumAlgorithm - The checksum algorithm to use
 * @returns The list of binaries extracted
 */
async function extractFromTar(url, binaries, dir, checksumAlgorithm) {
    const downloads = [];
    await (0, promises_2.pipeline)((0, download_1.startDownload)(url), (0, tar_1.extract)({
        cwd: dir,
        transform: (entry) => {
            const absolutePath = entry.absolute;
            if (!absolutePath) {
                throw new Error('Missing absolute path for entry');
            }
            if (checksumAlgorithm) {
                const hash = (0, node_crypto_1.createHash)(checksumAlgorithm);
                const passThrough = new minipass_1.Minipass({ async: true });
                passThrough.pipe(hash);
                passThrough.on('end', () => {
                    downloads.push({
                        path: absolutePath,
                        binary: entry.path,
                        checksum: hash.digest('hex'),
                    });
                });
                return passThrough;
            }
            // When no checksum is needed, record the entry and return undefined
            // to use the original stream without transformation
            downloads.push({
                path: absolutePath,
                binary: entry.path,
            });
            return undefined;
        },
    }, binaries));
    return downloads;
}
/**
 * Extracts the binaries from a zip archive.
 *
 * @param url - The URL of the archive to extract the binaries from
 * @param binaries - The list of binaries to extract
 * @param dir - The destination directory
 * @param checksumAlgorithm - The checksum algorithm to use
 * @returns The list of binaries extracted
 */
async function extractFromZip(url, binaries, dir, checksumAlgorithm) {
    const agent = new (url.protocol === 'http:' ? node_http_1.Agent : node_https_1.Agent)({
        keepAlive: true,
    });
    const source = {
        async size() {
            const download = (0, download_1.startDownload)(url, { agent, method: 'HEAD' });
            const response = await download.response();
            const contentLength = response.headers['content-length'];
            return contentLength ? parseInt(contentLength, 10) : 0;
        },
        stream(offset, bytes) {
            const options = {
                agent,
                headers: {
                    range: `bytes=${offset}-${bytes ? offset + bytes : ''}`,
                },
            };
            return (0, download_1.startDownload)(url, options);
        },
    };
    const { files } = await unzipper_1.Open.custom(source, {});
    const filtered = files.filter(({ path }) => binaries.includes((0, node_path_1.basename)(path, (0, node_path_1.extname)(path))));
    return await Promise.all(filtered.map(async ({ path, stream }) => {
        const dest = (0, node_path_1.join)(dir, path);
        const entry = stream();
        const destStream = (0, node_fs_1.createWriteStream)(dest);
        const binary = (0, node_path_1.basename)(path, (0, node_path_1.extname)(path));
        if (checksumAlgorithm) {
            const hash = (0, node_crypto_1.createHash)(checksumAlgorithm);
            const hashStream = async function* (entryStream) {
                for await (const chunk of entryStream) {
                    hash.update(chunk);
                    yield chunk;
                }
            };
            await (0, promises_2.pipeline)(entry, hashStream, destStream);
            return {
                path: dest,
                binary,
                checksum: hash.digest('hex'),
            };
        }
        await (0, promises_2.pipeline)(entry, destStream);
        return {
            path: dest,
            binary,
        };
    }));
}
//# sourceMappingURL=extract.cjs.map